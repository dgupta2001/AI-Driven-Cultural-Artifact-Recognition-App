{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rkJ3E8QQxEvemcGBtEoAiYtHfNsJQ4Jl",
      "authorship_tag": "ABX9TyOOp7ZJ/IDNyN1yTLPIUSeY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgupta2001/AI-Driven-Cultural-Artifact-Recognition-App/blob/main/Training_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tTjqpoJN2poF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8c6b56-0422-4f73-98c7-c96a0f001ffc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "rYISjcXl-ZJA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Set up the dataset path from Google Drive\n",
        "dataset_dir = '//content/drive/MyDrive/dataset'  # Your dataset folder with 8 subfolders\n",
        "\n",
        "# Step 4: Define the painting categories\n",
        "categories = ['gond', 'kalighat', 'kangra', 'kerala mural', 'madhubani', 'mandana', 'pichwai', 'warli']"
      ],
      "metadata": {
        "id": "cbNPLpmK-ZLV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Function to load and preprocess the images\n",
        "def load_images(dataset_dir, categories):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for category in categories:\n",
        "        path = os.path.join(dataset_dir, category)  # Navigate to the subfolder for each category\n",
        "        class_num = categories.index(category)  # Assign a numeric label to each category\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img))\n",
        "                img_array = cv2.resize(img_array, (128, 128))  # Resize images to 128x128\n",
        "                images.append(img_array)\n",
        "                labels.append(class_num)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image: {img} - {e}\")\n",
        "                pass\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "0mEpwEaZ-ZN4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Load the images and labels\n",
        "X, y = load_images(dataset_dir, categories)\n",
        "\n",
        "# Step 7: Normalize the images and convert labels to categorical\n",
        "X = X / 255.0\n",
        "y = to_categorical(y, num_classes=len(categories))\n",
        "\n",
        "# Step 8: Split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX5d2AaY-ZRA",
        "outputId": "d13c9531-7e67-462b-a6c4-f48d3e51732c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: gond72.gif - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: gond73.gif - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: kalighat230.jpg - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: kalighat52.gif - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "Error loading image: pageInfo.txt - OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(len(categories), activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKvISItr-ZTO",
        "outputId": "6c9b1b22-12a3-417b-fadc-855b9235915f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 11: Data augmentation to prevent overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "c8Ft1yGz-ZVb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Train the model\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ymu33jP-ZYB",
        "outputId": "9a82052e-ace1-4507-8fbb-0180ce2ded60"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 - 13s - 515ms/step - accuracy: 0.2312 - loss: 2.0754 - val_accuracy: 0.2953 - val_loss: 1.9703\n",
            "Epoch 2/20\n",
            "25/25 - 13s - 534ms/step - accuracy: 0.2247 - loss: 1.9662 - val_accuracy: 0.2850 - val_loss: 1.9366\n",
            "Epoch 3/20\n",
            "25/25 - 3s - 124ms/step - accuracy: 0.3091 - loss: 1.8848 - val_accuracy: 0.2591 - val_loss: 1.9089\n",
            "Epoch 4/20\n",
            "25/25 - 3s - 111ms/step - accuracy: 0.2896 - loss: 1.8683 - val_accuracy: 0.2902 - val_loss: 1.8781\n",
            "Epoch 5/20\n",
            "25/25 - 3s - 113ms/step - accuracy: 0.3234 - loss: 1.7816 - val_accuracy: 0.2902 - val_loss: 1.8643\n",
            "Epoch 6/20\n",
            "25/25 - 3s - 139ms/step - accuracy: 0.3481 - loss: 1.7533 - val_accuracy: 0.1969 - val_loss: 1.9745\n",
            "Epoch 7/20\n",
            "25/25 - 4s - 177ms/step - accuracy: 0.3649 - loss: 1.7428 - val_accuracy: 0.3109 - val_loss: 1.8892\n",
            "Epoch 8/20\n",
            "25/25 - 3s - 111ms/step - accuracy: 0.4052 - loss: 1.6588 - val_accuracy: 0.3161 - val_loss: 1.7629\n",
            "Epoch 9/20\n",
            "25/25 - 3s - 107ms/step - accuracy: 0.4182 - loss: 1.6047 - val_accuracy: 0.2953 - val_loss: 1.8385\n",
            "Epoch 10/20\n",
            "25/25 - 4s - 151ms/step - accuracy: 0.4364 - loss: 1.5784 - val_accuracy: 0.3938 - val_loss: 1.6677\n",
            "Epoch 11/20\n",
            "25/25 - 4s - 166ms/step - accuracy: 0.4377 - loss: 1.5658 - val_accuracy: 0.4145 - val_loss: 1.8108\n",
            "Epoch 12/20\n",
            "25/25 - 3s - 109ms/step - accuracy: 0.4779 - loss: 1.5413 - val_accuracy: 0.3886 - val_loss: 1.6667\n",
            "Epoch 13/20\n",
            "25/25 - 3s - 110ms/step - accuracy: 0.4727 - loss: 1.4844 - val_accuracy: 0.4767 - val_loss: 1.5134\n",
            "Epoch 14/20\n",
            "25/25 - 4s - 174ms/step - accuracy: 0.5000 - loss: 1.4117 - val_accuracy: 0.3368 - val_loss: 1.9676\n",
            "Epoch 15/20\n",
            "25/25 - 3s - 114ms/step - accuracy: 0.5143 - loss: 1.3693 - val_accuracy: 0.3057 - val_loss: 2.1795\n",
            "Epoch 16/20\n",
            "25/25 - 3s - 117ms/step - accuracy: 0.5182 - loss: 1.3567 - val_accuracy: 0.5337 - val_loss: 1.3752\n",
            "Epoch 17/20\n",
            "25/25 - 3s - 110ms/step - accuracy: 0.5299 - loss: 1.3332 - val_accuracy: 0.3731 - val_loss: 1.7700\n",
            "Epoch 18/20\n",
            "25/25 - 4s - 149ms/step - accuracy: 0.5286 - loss: 1.3521 - val_accuracy: 0.4974 - val_loss: 1.4190\n",
            "Epoch 19/20\n",
            "25/25 - 3s - 123ms/step - accuracy: 0.5182 - loss: 1.3427 - val_accuracy: 0.5181 - val_loss: 1.4022\n",
            "Epoch 20/20\n",
            "25/25 - 3s - 110ms/step - accuracy: 0.5675 - loss: 1.2089 - val_accuracy: 0.4456 - val_loss: 1.5700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Save the trained model to Google Drive\n",
        "model_save_path = '/content/drive/MyDrive/indian_paintings_recognition_model.h5'  # Path to save model in Google Drive\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(f\"Model saved at {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLB0gm2r6vlr",
        "outputId": "716d6f1f-ec7c-4071-e84b-d6098dfa4c36"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at /content/drive/MyDrive/indian_paintings_recognition_model.h5\n"
          ]
        }
      ]
    }
  ]
}